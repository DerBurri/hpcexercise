{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import tvm\n",
    "from tvm import te\n",
    "import tvm.relay as relay\n",
    "from tvm import rpc\n",
    "from tvm.contrib import utils, graph_executor as runtime\n",
    "from tvm.contrib.download import download_testdata\n",
    "\n",
    "# one line to get the model\n",
    "model_name = \"resnet18\"\n",
    "model = getattr(torchvision.models, model_name)(pretrained=True)\n",
    "model = model.eval()\n",
    "\n",
    "# We grab the TorchScripted model via tracing\n",
    "input_shape = [1, 3, 224, 224]\n",
    "input_data = torch.randn(input_shape)\n",
    "scripted_model = torch.jit.trace(model, input_data).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = \"https://github.com/dmlc/mxnet.js/blob/main/data/cat.png?raw=true\"\n",
    "img_name = \"cat.png\"\n",
    "img_path = download_testdata(img_url, img_name, module=\"data\")\n",
    "image = Image.open(img_path).resize((224, 224))\n",
    "\n",
    "\n",
    "def transform_image(image):\n",
    "    image = np.array(image) - np.array([123.0, 117.0, 104.0])\n",
    "    image /= np.array([58.395, 57.12, 57.375])\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    image = image[np.newaxis, :]\n",
    "    return image\n",
    "\n",
    "\n",
    "x = transform_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "synset_url = \"\".join(\n",
    "    [\n",
    "        \"https://gist.githubusercontent.com/zhreshold/\",\n",
    "        \"4d0b62f3d01426887599d4f7ede23ee5/raw/\",\n",
    "        \"596b27d23537e5a1b5751d2b0481ef172f58b539/\",\n",
    "        \"imagenet1000_clsid_to_human.txt\",\n",
    "    ]\n",
    ")\n",
    "synset_name = \"imagenet1000_clsid_to_human.txt\"\n",
    "synset_path = download_testdata(synset_url, synset_name, module=\"data\")\n",
    "with open(synset_path) as f:\n",
    "    synset = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = \"input0\"\n",
    "shape_list = [(input_name, x.shape)]\n",
    "mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)\n",
    "# we want a probability so add a softmax operator\n",
    "func = mod[\"main\"]\n",
    "func = relay.Function(func.params, relay.nn.softmax(func.body), None, func.type_params, func.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_classes = 1000\n",
    "image_shape = (3, 224, 224)\n",
    "data_shape = (batch_size,) + image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
     ]
    }
   ],
   "source": [
    "local_demo = False\n",
    "\n",
    "if local_demo:\n",
    "    target = tvm.target.Target(\"llvm\")\n",
    "else:\n",
    "    target = tvm.target.arm_cpu(\"rasp5\")\n",
    "    # The above line is a simple form of\n",
    "    # target = tvm.target.Target('llvm -device=arm_cpu -model=bcm2837 -mtriple=armv7l-linux-gnueabihf -mattr=+neon')\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(func, target, params=params)\n",
    "\n",
    "# After `relay.build`, you will get three return values: graph,\n",
    "# library and the new parameter, since we do some optimization that will\n",
    "# change the parameters but keep the result of model as the same.\n",
    "\n",
    "# Save the library at local temporary directory.\n",
    "tmp = utils.tempdir()\n",
    "lib_fname = tmp.relpath(\"net.tar\")\n",
    "lib.export_library(lib_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RPCError",
     "evalue": "Traceback (most recent call last):\n  6: _ZN3tvm7runtime13PackedFun\n  5: tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Module, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)>::AssignTypedLambda<tvm::runtime::__mk_TVM5::{lambda(tvm::runtime::Module, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)#1}>(tvm::runtime::__mk_TVM5::{lambda(tvm::runtime::Module, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)#1}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const\n  4: tvm::runtime::RPCWrappedFunc::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const\n  3: tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::function<void (tvm::runtime::TVMArgs)> const&)\n  2: tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::function<void (tvm::runtime::TVMArgs)>)\n  1: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::function<void (tvm::runtime::TVMArgs)>)\n  0: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::function<void (tvm::runtime::TVMArgs)>)\n  File \"/home/mburr/userdevtools/mambaforge/envs/tvm-build/conda-bld/tvm-package_1718725123204/work/src/runtime/rpc/rpc_endpoint.cc\", line 439\nRPCError: Error caught from RPC call:",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRPCError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# upload the library to remote device and load it\u001b[39;00m\n\u001b[1;32m     11\u001b[0m remote\u001b[38;5;241m.\u001b[39mupload(lib_fname)\n\u001b[0;32m---> 12\u001b[0m rlib \u001b[38;5;241m=\u001b[39m \u001b[43mremote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnet.tar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# create the remote runtime module\u001b[39;00m\n\u001b[1;32m     15\u001b[0m dev \u001b[38;5;241m=\u001b[39m remote\u001b[38;5;241m.\u001b[39mcpu(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/userdevtools/mambaforge/envs/eml/lib/python3.9/site-packages/tvm/rpc/client.py:178\u001b[0m, in \u001b[0;36mRPCSession.load_module\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a remote module, the file need to be uploaded first.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m        The remote module containing remote function.\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ffi_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadRemoteModule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mtvm/_ffi/_cython/./packed_func.pxi:332\u001b[0m, in \u001b[0;36mtvm._ffi._cy3.core.PackedFuncBase.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtvm/_ffi/_cython/./packed_func.pxi:263\u001b[0m, in \u001b[0;36mtvm._ffi._cy3.core.FuncCall\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtvm/_ffi/_cython/./packed_func.pxi:252\u001b[0m, in \u001b[0;36mtvm._ffi._cy3.core.FuncCall3\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtvm/_ffi/_cython/./base.pxi:182\u001b[0m, in \u001b[0;36mtvm._ffi._cy3.core.CHECK_CALL\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/userdevtools/mambaforge/envs/eml/lib/python3.9/site-packages/tvm/_ffi/base.py:481\u001b[0m, in \u001b[0;36mraise_last_ffi_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# The exception PyObject may contain a large amount of state,\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# including all stack frames that may be inspected in a later\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;66;03m# PDB post-mortem.  Therefore, we must make sure to remove the\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;66;03m# underlying PyObject* from the C++ side after we retrieve it.\u001b[39;00m\n\u001b[1;32m    479\u001b[0m _LIB\u001b[38;5;241m.\u001b[39mTVMDropLastPythonError()\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m py_err\n",
      "\u001b[0;31mRPCError\u001b[0m: Traceback (most recent call last):\n  6: _ZN3tvm7runtime13PackedFun\n  5: tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Module, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)>::AssignTypedLambda<tvm::runtime::__mk_TVM5::{lambda(tvm::runtime::Module, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)#1}>(tvm::runtime::__mk_TVM5::{lambda(tvm::runtime::Module, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)#1}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const\n  4: tvm::runtime::RPCWrappedFunc::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const\n  3: tvm::runtime::RPCClientSession::CallFunc(void*, TVMValue const*, int const*, int, std::function<void (tvm::runtime::TVMArgs)> const&)\n  2: tvm::runtime::RPCEndpoint::CallFunc(void*, TVMValue const*, int const*, int, std::function<void (tvm::runtime::TVMArgs)>)\n  1: tvm::runtime::RPCEndpoint::HandleUntilReturnEvent(bool, std::function<void (tvm::runtime::TVMArgs)>)\n  0: tvm::runtime::RPCEndpoint::EventHandler::HandleNextEvent(bool, bool, std::function<void (tvm::runtime::TVMArgs)>)\n  File \"/home/mburr/userdevtools/mambaforge/envs/tvm-build/conda-bld/tvm-package_1718725123204/work/src/runtime/rpc/rpc_endpoint.cc\", line 439\nRPCError: Error caught from RPC call:"
     ]
    }
   ],
   "source": [
    "# obtain an RPC session from remote device.\n",
    "if local_demo:\n",
    "    remote = rpc.LocalSession()\n",
    "else:\n",
    "    # The following is my environment, change this to the IP address of your target device\n",
    "    host = \"eml.local\"\n",
    "    port = 9090\n",
    "    remote = rpc.connect(host, port)\n",
    "\n",
    "# upload the library to remote device and load it\n",
    "remote.upload(lib_fname)\n",
    "rlib = remote.load_module(\"net.tar\")\n",
    "\n",
    "# create the remote runtime module\n",
    "dev = remote.cpu(0)\n",
    "module = runtime.GraphModule(rlib[\"default\"](dev))\n",
    "# set input data\n",
    "module.set_input(input_name, tvm.nd.array(x.astype(\"float32\")))\n",
    "# run\n",
    "module.run()\n",
    "# get output\n",
    "out = module.get_output(0)\n",
    "# get top1 result\n",
    "top1 = np.argmax(out.numpy())\n",
    "print(\"TVM prediction top-1: {}\".format(synset[top1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
